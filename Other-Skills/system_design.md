# System Design

### System Design Base

***
***
***
***

- 一、性能
  - 性能指标
    - 1. 响应时间
      - 指某个请求从发出到接收到响应消耗的时间。
      - 在对响应时间进行测试时，通常采用重复请求方式，然后计算平均响应时间。
    - 2. 吞吐量
      - 指系统在单位时间内可以处理的请求数量，通常使用每秒的请求数来衡量。
    - 3. 并发用户数
      - 指系统能同时处理的并发用户请求数量。
      - 在没有并发存在的系统中，请求被顺序执行，此时响应时间为吞吐量的倒数。例如系统支持的吞吐量为 100 req/s，那么平均响应时间应该为 0.01s。
      - 目前的大型系统都支持多线程来处理并发请求，多线程能够提高吞吐量以及缩短响应时间，主要有两个原因：
        - 多 CPU
        - IO 等待时间
      - 使用 IO 多路复用等方式，系统在等待一个 IO 操作完成的这段时间内不需要被阻塞，可以去处理其它请求。通过将这个等待时间利用起来，使得 CPU 利用率大大提高。
      - 并发用户数不是越高越好，因为如果并发用户数太高，系统来不及处理这么多的请求，会使得过多的请求需要等待，那么响应时间就会大大提高。
  - 性能优化
    - 1. 集群
      - 将多台服务器组成集群，使用负载均衡将请求转发到集群中，避免单一服务器的负载压力过大导致性能降低。
    - 2. 缓存
      - 缓存能够提高性能的原因如下：
        - 缓存数据通常位于内存等介质中，这种介质对于读操作特别快；
        - 缓存数据可以位于靠近用户的地理位置上；
        - 可以将计算结果进行缓存，从而避免重复计算。
    - 3. 异步
      - 某些流程可以将操作转换为消息，将消息发送到消息队列之后立即返回，之后这个操作会被异步处理。
- 二、伸缩性
  - 指不断向集群中添加服务器来缓解不断上升的用户并发访问压力和不断增长的数据存储需求。
  - 伸缩性与性能
    - 如果系统存在性能问题，那么单个用户的请求总是很慢的；
    - 如果系统存在伸缩性问题，那么单个用户的请求可能会很快，但是在并发数很高的情况下系统会很慢。
  - 实现伸缩性
    - 应用服务器只要不具有状态，那么就可以很容易地通过负载均衡器向集群中添加新的服务器。
    - 关系型数据库的伸缩性通过 Sharding 来实现，将数据按一定的规则分布到不同的节点上，从而解决单台存储服务器的存储空间限制。
    - 对于非关系型数据库，它们天生就是为海量数据而诞生，对伸缩性的支持特别好。
- 三、扩展性
  - 指的是添加新功能时对现有系统的其它应用无影响，这就要求不同应用具备低耦合的特点。
  - 实现可扩展主要有两种方式：
    - 使用消息队列进行解耦，应用之间通过消息传递进行通信；
    - 使用分布式服务将业务和可复用的服务分离开来，业务使用分布式服务框架调用可复用的服务。新增的产品可以通过调用可复用的服务来实现业务逻辑，对其它产品没有影响。

- 四、可用性
  - 冗余
    - 保证高可用的主要手段是使用冗余，当某个服务器故障时就请求其它服务器。
    - 应用服务器的冗余比较容易实现，只要保证应用服务器不具有状态，那么某个应用服务器故障时，负载均衡器将该应用服务器原先的用户请求转发到另一个应用服务器上，不会对用户有任何影响。
    - 存储服务器的冗余需要使用主从复制来实现，当主服务器故障时，需要提升从服务器为主服务器，这个过程称为切换。
  - 监控
    - 对 CPU、内存、磁盘、网络等系统负载信息进行监控，当某个数据达到一定阈值时通知运维人员，从而在系统发生故障之前及时发现问题。
  - 服务降级
    - 服务降级是系统为了应对大量的请求，主动关闭部分功能，从而保证核心功能可用。
- 五、安全性
  - 要求系统在应对各种攻击手段时能够有可靠的应对措施。

### 分布式

负载均衡
分布式锁

### 集群


### 攻击技术

- 跨站脚本攻击（Cross-Site Scripting, XSS）
- 跨站请求伪造（Cross-site request forgery，CSRF）
- SQL 注入攻击
- 拒绝服务攻击（denial-of-service attack，DoS）
- 分布式拒绝服务攻击（distributed denial-of-service attack，DDoS）
- 中间人攻击（Man-in-the-middle attack，通常缩写为MITM）

### 缓存

缓存
LRU
- 缓存位置
  - 浏览器
  - ISP
  - 反向代理
  - 本地缓存
  - 分布式缓存
  - 数据库缓存
- CDN，内容分发网络（Content distribution network）


### 消息队列

kafka redis

- 消息模型
  - 点对点
  - 发布/订阅

***
***
***
***


# 一、消息模型

## 点对点

消息生产者向消息队列中发送了一个消息之后，只能被一个消费者消费一次。

<div align="center"> <img src="system_design/685a692f-8f76-4cac-baac-b68e2df9a30f.jpg"/> </div><br>

## 发布/订阅

消息生产者向频道发送一个消息之后，多个消费者可以从该频道订阅到这条消息并消费。

<div align="center"> <img src="system_design/ddb5ff4c-4ada-46aa-9bf1-140bdb5e4676.jpg"/> </div><br>

发布与订阅模式和观察者模式有以下不同：

- 观察者模式中，观察者和主题都知道对方的存在；而在发布与订阅模式中，发布者与订阅者不知道对方的存在，它们之间通过频道进行通信。
- 观察者模式是同步的，当事件触发时，主题会调用观察者的方法，然后等待方法返回；而发布与订阅模式是异步的，发布者向频道发送一个消息之后，就不需要关心订阅者何时去订阅这个消息，可以立即返回。

<div align="center"> <img src="system_design/bee1ff1d-c80f-4b3c-b58c-7073a8896ab2.jpg"/> </div><br>

# 二、使用场景

## 异步处理

发送者将消息发送给消息队列之后，不需要同步等待消息接收者处理完毕，而是立即返回进行其它操作。消息接收者从消息队列中订阅消息之后异步处理。

例如在注册流程中通常需要发送验证邮件来确保注册用户身份的合法性，可以使用消息队列使发送验证邮件的操作异步处理，用户在填写完注册信息之后就可以完成注册，而将发送验证邮件这一消息发送到消息队列中。

只有在业务流程允许异步处理的情况下才能这么做，例如上面的注册流程中，如果要求用户对验证邮件进行点击之后才能完成注册的话，就不能再使用消息队列。

## 流量削锋

在高并发的场景下，如果短时间有大量的请求到达会压垮服务器。

可以将请求发送到消息队列中，服务器按照其处理能力从消息队列中订阅消息进行处理。

## 应用解耦

如果模块之间不直接进行调用，模块之间耦合度就会很低，那么修改一个模块或者新增一个模块对其它模块的影响会很小，从而实现可扩展性。

通过使用消息队列，一个模块只需要向消息队列中发送消息，其它模块可以选择性地从消息队列中订阅消息从而完成调用。

# 三、可靠性

## 发送端的可靠性

发送端完成操作后一定能将消息成功发送到消息队列中。

实现方法：

- 在本地数据库建一张消息表，将消息数据与业务数据保存在同一数据库实例里，这样就可以利用本地数据库的事务机制。事务提交成功后，将消息表中的消息转移到消息队列中，若转移消息成功则删除消息表中的数据，否则继续重传。

## 接收端的可靠性

接收端能够从消息队列成功消费一次消息。

两种实现方法：

- 保证接收端处理消息的业务逻辑具有幂等性：只要具有幂等性，那么消费多少次消息，最后处理的结果都是一样的。
- 保证消息具有唯一编号，并使用一张日志表来记录已经消费的消息编号。


***
***
***
***


### 中间件

。。。 。。。

### Interview Problem
